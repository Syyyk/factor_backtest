// drop database "dfs://Daily"

fileFolder = "E:/StockData/Daily/"  // Change to your folder

// Create Database
dbPath = "dfs://Daily"
db = database(dbPath, HASH, [DATE, 100])

// Add stock table
colNames = `InstrumentId`TradeDate`Open`High`Low`Close`Volume`Amount`Size`FloatSize`MarketType`TradeState`PriceType
colTypes = [INT, DATE, DOUBLE, DOUBLE, DOUBLE, DOUBLE, INT, DOUBLE, DOUBLE, DOUBLE, INT, INT, INT]
schema = table(10000:0, colNames, colTypes)
pt = db.createPartitionedTable(schema, `Stock, `TradeDate)

// Load text
// Some fields in CSMAR daily data
// market_type 1=上证A股市场(不包含科创板) 2=上证B股市场 4=深证A股市场(不包含创业板) 8=深证B股市场 16=创业板 32=科创板 64=北证A股市场
// trade_state 1=正常交易 2=ST 3=*ST 
filePath = fileFolder + "Stock_Daily.csv"
data = loadText(filename=filePath)

// Insert
batchSize = 1000000  // append in batches since the dataset is too large
numRows = size(data)
start_row = 0
do {
    end_row = min(start_row + batchSize, numRows)
    append!(pt, data[start_row:(end_row-1)])
    start_row += batchSize
} while (start_row < numRows)

// Add index table
colNames = `InstrumentID`TradeDate`Open`High`Low`Close`Volume`Amount
colTypes = [INT, DATE, DOUBLE, DOUBLE, DOUBLE, DOUBLE, INT, DOUBLE]
schema = table(10000:0, colNames, colTypes)
pt = db.createPartitionedTable(schema, `Index, `TradeDate)

filePath = fileFolder + "Index_Daily.csv"
data = loadText(filename=filePath)
append!(pt, data)

// Test
ppt = loadTable(db, `Stock)
select * from ppt where amount>10000000000

